<?xml version="1.0" encoding="UTF-8"?>
<?xml-stylesheet type="text/xsl" href="configuration.xsl"?>
<!--
  Licensed under the Apache License, Version 2.0 (the "License");
  you may not use this file except in compliance with the License.
  You may obtain a copy of the License at

    http://www.apache.org/licenses/LICENSE-2.0

  Unless required by applicable law or agreed to in writing, software
  distributed under the License is distributed on an "AS IS" BASIS,
  WITHOUT WARRANTIES OR CONDITIONS OF ANY KIND, either express or implied.
  See the License for the specific language governing permissions and
  limitations under the License. See accompanying LICENSE file.
-->

<!-- Put site-specific property overrides in this file. -->

<configuration>
	<!-- name node 存放目录 -->
	<property>
		<name>dfs.name.dir</name>
		<value>/usr/local/xj/hadoopDir/nameNode</value>
	</property>
	<!-- data node 存放目录 -->
	<property>
                <name>dfs.data.dir</name>
                <value>/usr/local/xj/hadoopDir/dataNode</value>
        </property>
	<!-- 指定 secondarynameNode 的地址-->
<!--	<property>
                <name>dfs.namenode.secondary.http-address</name>
                <value>slave1:50090</value>
        </property> -->
	<!--命名服务的逻辑名称 ，如果要起动Federation ，就在这里添加多个命名服务名称，用逗号分隔-->
	<property>
		<name>dfs.nameservices</name>
		<value>myha</value>
	</property>
	<!--某个命名服务器下面的2个namenode ，一个命名服务下面最多能有2个节点-->
	<property>
                <name>dfs.ha.namenodes.myha</name>
                <value>master,secondary</value>
        </property>
	<property>
                <name>dfs.namenode.rpc-address.myha.master</name>
                <value>master:9000</value>
        </property>
	<property>
                <name>dfs.namenode.rpc-address.myha.secondary</name>
                <value>secondary:9000</value>
        </property>
	<property>
                <name>dfs.namenode.http-address.myha.master</name>
                <value>master:50070</value>
        </property>

	<property>
                <name>dfs.namenode.http-address.myha.secondary</name>
                <value>secondary:50070</value>
        </property>
	<property>
		<name>dfs.namenode.shared.edits.dir</name>
		<value>qjournal://master:8485;secondary:8485;slave1:8485/myha</value>
	</property>
	<!-- journalnode  存放文件节点目录 -->
	<property>  
		<name>dfs.journalnode.edits.dir</name>  
		<value>/usr/local/xj/hadoopDir/journal</value>  
	</property>
	<!--DFS 通过该类来查找当前的actige namenode --> 
	<property>
		<name>dfs.client.failover.proxy.provider.myha</name>
		<value>org.apache.hadoop.hdfs.server.namenode.ha.ConfiguredFailoverProxyProvider</value>
 	</property>
	<!--主机挂掉 -->
	<property>  
      		<name>dfs.ha.fencing.methods</name>  
     		<value>sshfence</value>  
	</property>  
	<!--主机私钥-->  
	<property>  
      		<name>dfs.ha.fencing.ssh.private-key-files</name>  
      		<value>/usr/local/xj/.ssh/id_rsa</value>  
	</property>  
 	<property>  
      		<name>dfs.ha.fencing.ssh.connect-timeout</name>  
      		<value>30000</value>  
	</property> 
	<!--设置namenode 故障 自动转移 -->	
	<property>
 		<name>dfs.ha.automatic-failover.enabled</name>
  		<value>true</value>
	</property>
	<!--  设置 secondaryNameNode checkpoint 目录 -->
<!--	<property>
		<name>dfs.checkpoint.dir</name>
		<value>/home/hadoop/check</value>
	</property> -->
	<!-- 设置副本数量 -->
	<property>
		<name>dfs.replication</name>
		<value>3</value>
	</property>
        <!-- 指定节点白名单 -->
        <property>
		<name>dfs.hosts</name>
		<value>/usr/local/xj/hadoop/etc/hadoop/slaves</value>
	</property> 
        <!-- 指定节点黑名单 -->
	<!-- <property>
		<name>dfs.hosts.exclude</name>
		<value>/usr/local/hadoop/etc/hadoop/exclude</value>
	</property> -->
</configuration>
